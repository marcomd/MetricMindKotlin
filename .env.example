# Database Connection Configuration
# Option 1: Use DATABASE_URL (recommended for remote/hosted databases like Neon, Heroku, etc.)
# DATABASE_URL=postgresql://user:password@host:port/database?sslmode=require

# Option 2: Use individual connection parameters (local development)
PGHOST=localhost
PGPORT=5432
PGDATABASE=git_analytics
PGUSER=your_username
PGPASSWORD=your_password

# Note: DATABASE_URL takes priority over individual parameters if both are set

# PostgreSQL Test Database Configuration
PGDATABASE_TEST=git_analytics_test

# Optional: Default extraction dates
DEFAULT_FROM_DATE="6 months ago"
DEFAULT_TO_DATE="now"

# Optional: Output directory for JSON exports
OUTPUT_DIR=./data/exports

# AI Categorization Configuration
# Set AI_PROVIDER to enable AI-powered categorization (leave empty to disable)
AI_PROVIDER=ollama                    # Options: gemini, ollama (leave empty to disable)
AI_TIMEOUT=30                         # Timeout in seconds (default: 30)
AI_RETRIES=3                          # Retry attempts on failure (default: 3)
PREVENT_NUMERIC_CATEGORIES=true       # Reject numeric categories like "2023" or "#6802" (default: true)

# Gemini Configuration (Google Generative AI)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.0-flash-exp    # Model name (default: gemini-2.0-flash-exp)
GEMINI_TEMPERATURE=0.1               # Temperature 0.0-2.0 (default: 0.1 for consistent results)

# Ollama Configuration (Local LLM)
OLLAMA_URL=http://localhost:11434    # Ollama server URL (default: http://localhost:11434)
OLLAMA_MODEL=llama2                  # Model name (e.g., llama2, mistral, gpt-oss:20b-cloud)
OLLAMA_TEMPERATURE=0.1               # Temperature 0.0-2.0 (default: 0.1 for consistent results)

# Debug mode (optional)
# AI_DEBUG=true                      # Enable verbose logging for AI operations
